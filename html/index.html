<html>
<head>
<title>Computer Vision Project</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 960px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

td img {
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Junxian Wu <span style="color: #DE3737">(jwu317)</span></h1>
</div>
</div>
<div class="container">

<h2>CS 4495 / 6476 Project 2: Local Feature Matching</h2>

<!-- <div style="float: right; padding: 20px">
<img src="placeholder.jpg" />
<p style="font-size: 14px">Example of a right floating element.</p>
</div>
 -->
<p> 	For this project, the whole pipeline of image feature matching is created to match the image pair of the same main objects. The whole process has three main steps.</p>

<ol>
<li>Choose interested points of both images</li>
<li>Extract the feature of each interested points</li>
<li>Match the insterested points according to their features</li>
</ol>

<!-- <p> 	Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> -->

<div style="clear:both">
<div style="float: left; padding: 20px">
<img src="fp1_ND.jpg" />
<p style="font-size: 14px">Interested points of Notre Dame Image Pairs (I)</p>
<img src="fp2_ND.jpg" />
<p style="font-size: 14px">Interested points of Notre Dame Image Pairs (II)</p>
</div>
<h3>Choosing interested points</h3>

<p> 	Harris Corner Dictector was used to choose interested points. The idea to calculate the cornerness of a certain pixel by using second moment matrix. However, it is not possible to process all the corners. To filter out the interested points, the local maximum of cornerness was calculated to reduce the possible corner. Two methods were tried to accomplish the non-maxima suppresion of the cornerness. 
The first one is using sliding window to restrict the local region and to find the maxima </p>

<p> 	The first one is using sliding window to restrict the local region and to find the maxiam in that region. In this way, the number of points generated will depend on the size of sliding window. Also, the points will distribute over the image because the window will scan every block in the image.</p>

<p> 	The second one is using connected components concept to restrict the local region. First, the image was transformed to binary image by using thershold. For the pixel that has cornerness lower than thershold, we label it as 0. For the pixel that has cornerness higher that thershold, we label it as 1. With the help of BWCONNCOMP function, we can find out the connected components among the pixels that have cornerness higher than thershold. After that, we calculate the maxima of the cornerness in each of these connected components. Therefore, each connected components will generate one local maxima as points of interest. </p>

<p> 	In here, the second method was choosen as the method used in pipeline. The sliding window method will include more unnecessary corner in some flat region. However, the connected components method will only pick the point from high cornerness region, which is more reasonable and fast. More efficient interested points make the calculation of features more efficient too. </p>


<div style="clear:both">

<h3>Extracting the feature of each interested points</h3>

<p> 	The features interested points were extracted as a discriptor of the pixels around interested point. Each discriptor has 4 x 4 cell to roughly indicate the spatial feature of pxiels. Each cell will store an 8 dimension histogram that describes the direction of the gradient on each pixel. To simplify the process. The magnitude of the gradient was added to the nearest 2 directions of four nearest cells (in terms of space). Therefore, each gradient of the pixel has contribution to both difference in terms of space and color. </p>

<h3>Matching the interested points according to their features</h3>

<p> 	The matching alrogithm is to calculate the Eulicdean distance between the features of each interested point pair, and the least distance pair were picked as matching pair. To rank the matching, the confidence of each match was calculated. The Nearest Distance ratio test was used to evaluate the confidence of matches. The smaller the ratio, the higher confidence of the points.</p>


<h3>Decision & Tuning</h3>
<p> 	The tuning of the parameters was all finished with Norte Dame images pair. In the first hand result, the first 100 confident points, the good match rate is not satisfied 68 good match out of 100 match pair). To tune the algorithm. the thershold of Non-maxima suppression had been set at 0.0000001. And the alpha value was tuned to 0.05. The gaussian filter used to blur the gradient image was tuned as 0.2 varience. After all the tuning, the matching rate of first 100 points raised from 68 to 88.</p>

<p> 	The algorithm at first can only process grayscale images. The total amount of interested points was limited because it only found points in one layer. At first, the thershold of connect components method was lower to include more point. However, the points we received from this modification did not acutally include useful features. To increase the amount of interested points, the algorithm was modified to calculate colored version of image. All the interested points in three layers of image are all included. Also, in the features extraction, the gradients of all three layers are all included. The calculation was longer but the the match rate increased from 88% to 94%. </p>

<h3>Result</h3>
<div style="float: center; padding: 20px">
<img src="NotreDame_eval_color.jpg" />
<center><p style="font-size: 14px">Match pairs of Norte Dame images pair</p></center>
</div>
<p> The first 100 match pairs was evaluated for the Norte Dame images pair. There are 94 good matches out of 100 matches. The points with green cricumferen are good matches. The good matches are more concentrated in the left side of the image.</p>

<div style="float: left; padding: 20px">
<img src="Mount_RushMore_eval_color_200.jpg" />
<center><p style="font-size: 14px">Match pairs of Mount Rushmore images pair</p></center>
</div>
<p> Grayscale mode is already good enough for the Mount Rushmore pair, so only the grayscale match result was shown. The first 100 match pairs was evaluated for the Mount Rushmore images pair. There are 99 good matches out of 100 matches. The points with green cricumferen are good matches. The good matches are more concentrated in the left side of the image. The first 500 matches was also examined. There are 467 good matches in the first 500 matches, which is 93.4% good match rate.</p>

<div style="float: left; padding: 20px">
<img src="eval_color_EpiscopalGaudi.jpg" />
<center><p style="font-size: 14px">Match pairs of Episcopal Gaudi images pair</p></center>
</div>
<p> The first 100 match pairs was evaluated for the Episcopal Gaudi images pair. However, only 16 good matches out of 100 matches. This image pair is more challenging to match for several reasons. First, the different size of two images will make some corners harder to match. Scaling will make some corners becomes edges. Also, the rotation of Episcopal Gaudi makes the features matching harder with SIFT vectors. Some advanced algorithm can make the interested point.</p>

<p> Here, the larger image was simply resized to match the smaller image, and then the color algorithm was run on the images pair too. For the first 100 matches, the good match raised from 16% to 69%. It is still not satisfied but already improved a lot. Another to improve the result is to set the feature width for the larger image larger according to the ratio of their sizes. The result raised from 16% to 40%. It performed not as good as directly resize the image</p>

<div style="float: left; padding: 20px">
<img src="eval_color_EpiscopalGaudi_best.jpg" />
<center><p style="font-size: 14px">Match pairs of Episcopal Gaudi images pair, larger image was resized.</p></center>
</div>

<div style="float: left; padding: 20px">
<img src="diffFeatureWeight_eval.jpg" />
<center><p style="font-size: 14px">Match pairs of Episcopal Gaudi images pair, larger image used larger feature width</p></center>
</div>

<!-- <h3>Results in a table</h3>

<table border=1>
<tr>
<td>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg"  width="24%"/>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg" width="24%"/>
</td>
</tr>

<tr>
<td>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg"  width="24%"/>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg" width="24%"/>
</td>
</tr>

</table>

<div style="clear:both" >
<p> 	Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div> -->
</body>
</html>
